{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ea915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0564475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466951bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a151547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x=Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    \n",
    "    x=Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b848f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x=conv_block(inputs, num_filters)\n",
    "    p=MaxPool2D((2,2))(x)\n",
    "    \n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126cd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x=Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(inputs)\n",
    "    x=Concatenate()([x, skip_features])\n",
    "    x=conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c8d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 256 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 1)  65          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 15,336,513\n",
      "Trainable params: 15,330,625\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\"Encoder\"\"\"\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    \"\"\"Bridge\"\"\"\n",
    "    b1=conv_block(p4, 1024)\n",
    "    \n",
    "    \"\"\"Decoder\"\"\"\n",
    "    d1=decoder_block(b1, s4, 512)\n",
    "    d2=decoder_block(d1, s3, 256)\n",
    "    d3=decoder_block(d2, s2, 128)\n",
    "    d4=decoder_block(d3, s1, 64)\n",
    "    \n",
    "    \"\"\"Output\"\"\"\n",
    "    outputs=Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    \n",
    "    model=Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "if __name__== \"__main__\":\n",
    "    input_shape= (512, 512, 3)\n",
    "    model=build_unet(input_shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd7c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62750b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4542 - Masks: 4542\n",
      "Training: 1136 - Masks: 1136\n",
      "WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x000001848A911558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <function preprocess at 0x000001848A911558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "Train Steps:  379\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    images = sorted(glob(os.path.join(dataset_path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(dataset_path, \"masks/*\")))\n",
    "    \n",
    "    train_x, test_x= train_test_split(images, test_size=0.2, random_state=42)\n",
    "    train_y, test_y= train_test_split(masks, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    x= cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x= cv2.resize(x, (256,256))\n",
    "    x= x/255.0 #normalization stage\n",
    "    x=x.astype(np.float32)  #Converts image to (256,256,3)\n",
    "    return x\n",
    "def read_mask(path):\n",
    "    x= cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x= cv2.resize(x, (256,256)) #Grayscale already puts image in range of zero and 1 so no need for normalization\n",
    "    x= x.astype(np.float32)   #converts image to (256,256)\n",
    "    x= np.expand_dims(x, axis=-1)    #converts image from (256,256) to (256,256,1)\n",
    "    return x\n",
    "    \n",
    "def preprocess(image_path, mask_path):\n",
    "    def f(image_path, mask_path):\n",
    "        image_path= image_path.decode()\n",
    "        mask_path= mask_path.decode()\n",
    "            \n",
    "        x= read_image(image_path)\n",
    "        y= read_mask(mask_path)\n",
    "            \n",
    "        return x,y\n",
    "        \n",
    "    image, mask= tf.numpy_function(f, [image_path, mask_path], [tf.float32, tf.float32])\n",
    "    image.set_shape([256,256,3])\n",
    "    mask.set_shape([256,256,1])\n",
    "        \n",
    "    return image, mask\n",
    "    \n",
    "def tf_dataset(images, masks, batch=8):\n",
    "    dataset= tf.data.Dataset.from_tensor_slices((images, masks))\n",
    "    dataset= dataset.shuffle(buffer_size=5000)\n",
    "    dataset= dataset.map(preprocess)\n",
    "    dataset= dataset.batch(batch)\n",
    "    dataseta= dataset.prefetch(2)\n",
    "    return dataset\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path=\"archive/people_segmentation\"\n",
    "    (train_x, train_y), (test_x, test_y)= load_data(dataset_path)\n",
    "    \n",
    "    \n",
    "    print(f\"Training: {len(train_x)} - Masks: {len(train_y)}\")\n",
    "    print(f\"Training: {len(test_x)} - Masks: {len(test_y)}\")\n",
    "    \n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=12)\n",
    "    #for image, mask in train_dataset:\n",
    "       # print(image.shape, mask.shape)\n",
    "        \n",
    "    \"\"\"\n",
    "    10 - elements\n",
    "    batch - 3\n",
    "    10//3=3\n",
    "    3*3=9\n",
    "    3+1\n",
    "    \"\"\"\n",
    "    batch=12\n",
    "    train_steps=len(train_x)//batch\n",
    "    if len(train_x) % batch!=0:\n",
    "        train_steps+=1\n",
    "        \n",
    "    print(\"Train Steps: \", train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6c2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59aa470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \"\"\"Hyperparameters\"\"\"\n",
    "    dataset_path=\"archive/people_segmentation\"\n",
    "    input_shape= (256,256,3)\n",
    "    batch_size=8\n",
    "    epochs=10\n",
    "    lr=1e-4\n",
    "    model_path=\"unet.h5\"\n",
    "    csv_path=\"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "756f2c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4542 - 4542\n",
      "Testing: 1136 - 1136\n"
     ]
    }
   ],
   "source": [
    "\"\"\"loading the dataset\"\"\"\n",
    "(train_x, train_y), (test_x, test_y)= load_data(dataset_path)\n",
    "print (f\"Training: {len(train_x)} - {len(train_y)}\")\n",
    "print (f\"Testing: {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "train_dataset=tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset=tf_dataset(test_x, test_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e17873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b91007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Model\"\"\"\n",
    "model=build_unet(input_shape)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision() \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f38bbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 379 steps, validate for 142 steps\n",
      "Epoch 1/10\n",
      "378/379 [============================>.] - ETA: 10s - loss: 0.4290 - mean_io_u: 0.3727 - recall: 0.5426 - precision: 0.6392\n",
      "Epoch 00001: saving model to unet.h5\n",
      "379/379 [==============================] - 4231s 11s/step - loss: 0.4289 - mean_io_u: 0.3727 - recall: 0.5427 - precision: 0.6393 - val_loss: 0.4261 - val_mean_io_u: 0.3721 - val_recall: 0.3930 - val_precision: 0.7283\n",
      "Epoch 2/10\n",
      "189/379 [=============>................] - ETA: 30:26 - loss: 0.3663 - mean_io_u: 0.3714 - recall: 0.6099 - precision: 0.7151WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3790 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00002: saving model to unet.h5\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,mean_io_u,recall,precision,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mean_io_u,recall,precision,lr\n",
      "189/379 [=============>................] - ETA: 30:27 - loss: 0.3663 - mean_io_u: 0.3714 - recall: 0.6099 - precision: 0.7151"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x184912bbac8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks=[\n",
    "    ModelCheckpoint(model_path, monitor=\"val_loss\", verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.1, verbose=1),\n",
    "    CSVLogger(csv_path), \n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "]\n",
    "\n",
    "train_steps=len(train_x)//batch\n",
    "if len(train_x) % batch!=0:\n",
    "    train_steps+=1\n",
    "    \n",
    "valid_steps=len(test_x)//batch_size\n",
    "if len(test_x)%batch_size!=0:\n",
    "    valid_steps+=1\n",
    "\n",
    "model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=valid_steps,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c3ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a9c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c28902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_images=glob(\"images/*\")\n",
    "    \n",
    "    model=tf.keras.models.load_model(\"unet.h5\")\n",
    "    \n",
    "    for path in tqdm (test_images, total=len(test_images)):\n",
    "        x=cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        original_image=x\n",
    "        h, w, _=x.shape\n",
    "        \n",
    "        x=cv2.resize(x, (256,256))\n",
    "        x=x/255.0\n",
    "        x=x.astype(np.float32)\n",
    "        \n",
    "        #To convert (256, 256, 3) into (1, 256, 256, 3)\n",
    "        x=np.expand_dims(x, axis=0)\n",
    "        \n",
    "        pred_mask=model.predict(x)\n",
    "        \n",
    "        #To convert (1, 256, 256, 1) into (256, 256, 1)\n",
    "        pred_mask=pred_mask[0]\n",
    "        \n",
    "        #To convert into (256, 256, 3)\n",
    "        \n",
    "        pred_mask=np.concatenate(\n",
    "            [\n",
    "                pred_mask, pred_mask, pred_mask\n",
    "            ], axis=2\n",
    "        )\n",
    "        \n",
    "        pred_mask= pred_mask>0.5 * 255\n",
    "        pred_mask= pred_mask.astype(np.float32)\n",
    "        pred_mask=cv2.resize(pred_mask, (w,h))\n",
    "        \n",
    "        original_image=original_image.astype(np.float32)\n",
    "        \n",
    "        alpha=0.6\n",
    "        cv2.addWeighted(pred_mask, alpha, original_image, 1-alpha, 0, original_image )\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        images/1.png\n",
    "        \n",
    "        \"\"\"\n",
    "        name=path.split(\"/\")[-1] #[\"images\", \"1.jpg\"]\n",
    "        cv2.imwrite(f\"save_images/{name}\", original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf081e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
