{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740048d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4542 - Masks: 4542\n",
      "Training: 1136 - Masks: 1136\n",
      "WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x000001DE208CDA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <function preprocess at 0x000001DE208CDA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "Train Steps:  379\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    images = sorted(glob(os.path.join(dataset_path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(dataset_path, \"masks/*\")))\n",
    "    \n",
    "    train_x, test_x= train_test_split(images, test_size=0.2, random_state=42)\n",
    "    train_y, test_y= train_test_split(masks, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    x= cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x= cv2.resize(x, (256,256))\n",
    "    x= x/255.0 #normalization stage\n",
    "    x=x.astype(np.float32)  #Converts image to (256,256,3)\n",
    "    return x\n",
    "def read_mask(path):\n",
    "    x= cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x= cv2.resize(x, (256,256)) #Grayscale already puts image in range of zero and 1 so no need for normalization\n",
    "    x= x.astype(np.float32)   #converts image to (256,256)\n",
    "    x= np.expand_dims(x, axis=-1)    #converts image from (256,256) to (256,256,1)\n",
    "    return x\n",
    "    \n",
    "def preprocess(image_path, mask_path):\n",
    "    def f(image_path, mask_path):\n",
    "        image_path= image_path.decode()\n",
    "        mask_path= mask_path.decode()\n",
    "            \n",
    "        x= read_image(image_path)\n",
    "        y= read_mask(mask_path)\n",
    "            \n",
    "        return x,y\n",
    "        \n",
    "    image, mask= tf.numpy_function(f, [image_path, mask_path], [tf.float32, tf.float32])\n",
    "    image.set_shape([256,256,3])\n",
    "    mask.set_shape([256,256,1])\n",
    "        \n",
    "    return image, mask\n",
    "    \n",
    "def tf_dataset(images, masks, batch=8):\n",
    "    dataset= tf.data.Dataset.from_tensor_slices((images, masks))\n",
    "    dataset= dataset.shuffle(buffer_size=5000)\n",
    "    dataset= dataset.map(preprocess)\n",
    "    dataset= dataset.batch(batch)\n",
    "    dataseta= dataset.prefetch(2)\n",
    "    return dataset\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path=\"archive/people_segmentation\"\n",
    "    (train_x, train_y), (test_x, test_y)= load_data(dataset_path)\n",
    "    \n",
    "    \n",
    "    print(f\"Training: {len(train_x)} - Masks: {len(train_y)}\")\n",
    "    print(f\"Training: {len(test_x)} - Masks: {len(test_y)}\")\n",
    "    \n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=12)\n",
    "    #for image, mask in train_dataset:\n",
    "       # print(image.shape, mask.shape)\n",
    "        \n",
    "    \"\"\"\n",
    "    10 - elements\n",
    "    batch - 3\n",
    "    10//3=3\n",
    "    3*3=9\n",
    "    3+1\n",
    "    \"\"\"\n",
    "    batch=12\n",
    "    train_steps=len(train_x)//batch\n",
    "    if len(train_x) % batch!=0:\n",
    "        train_steps+=1\n",
    "        \n",
    "    print(\"Train Steps: \", train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
